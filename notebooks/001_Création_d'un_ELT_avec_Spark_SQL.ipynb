{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693cefa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Hello, World from Scala kernel!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77739d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.{DataFrame, SparkSession}\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{DataFrame, SparkSession};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56005464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extract: (spark: org.apache.spark.sql.SparkSession)org.apache.spark.sql.DataFrame\n",
       "load: (titanic: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n",
       "transform: (titanic: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n",
       "typeVariables: (titanic: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n",
       "translateToEnglish: (titanic: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract(spark: SparkSession): DataFrame = {\n",
    "        // load titanic files as DataFrames\n",
    "        val titanicPart1 = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/titanic_part_1.txt\")\n",
    "        val titanicPart2 = spark.read.format(\"parquet\").load(\"data/titanic_part_2.parquet\")\n",
    "        val titanicPart3 = spark.read.format(\"orc\").load(\"data/titanic_part_3.orc\")\n",
    "\n",
    "        // combine DataFrames\n",
    "        val titanic = titanicPart1.union(titanicPart2).union(titanicPart3)\n",
    "\n",
    "        titanic\n",
    "    }\n",
    "\n",
    "    def load(titanic: DataFrame): DataFrame = {\n",
    "        // write dataframe to csv\n",
    "        titanic.write.format(\"csv\").option(\"header\", \"true\").save(\"data/titanic.csv\")\n",
    "\n",
    "        titanic\n",
    "    }\n",
    "\n",
    "    def transform(titanic: DataFrame): DataFrame = {\n",
    "        val typedTitanic = typeVariables(titanic)\n",
    "        val translatedTitanic = translateToEnglish(typedTitanic)\n",
    "        \n",
    "        translatedTitanic\n",
    "    }\n",
    "\n",
    "    def typeVariables(titanic: DataFrame): DataFrame = {\n",
    "        val typedTitanic = titanic.select(titanic.columns.map {\n",
    "            case column@(\"PassengerId\" | \"Survived\" | \"Pclass\" | \"SibSp\" | \"Parch\") => titanic(column).cast(\"int\").as(column)\n",
    "            case column@(\"Age\" | \"Fare\") => titanic(column).cast(\"double\").as(column)\n",
    "            case column => titanic(column).cast(\"string\").as(column)\n",
    "        }:_*)\n",
    "\n",
    "        typedTitanic\n",
    "    }\n",
    "\n",
    "    def translateToEnglish(titanic: DataFrame): DataFrame = {\n",
    "        titanic\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc5dd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extractedTitanic: org.apache.spark.sql.DataFrame = [PassengerId: string, Survived: string ... 10 more fields]\n",
       "loadedTitanic: org.apache.spark.sql.DataFrame = [PassengerId: string, Survived: string ... 10 more fields]\n",
       "transformedTitanic: Unit = ()\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var extractedTitanic = extract(spark)\n",
    "var loadedTitanic = load(extractedTitanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40bc7baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loadedTitanic.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b45a1f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformedTitanic: org.apache.spark.sql.DataFrame = [PassengerId: int, Survived: int ... 10 more fields]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var transformedTitanic = transform(loadedTitanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d753d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformedTitanic.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e2c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
